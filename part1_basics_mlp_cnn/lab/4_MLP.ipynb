{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptron\n",
    "\n",
    "* Perceptron dates back to 1960s and considered first generation Neural Networks modeled after our brain cells.\n",
    "\n",
    "* The Goal of Perceptron is to solve the problem of Classification where data $x \\in \\mathbb{R}^d$ and labels $y \\in \\{\\pm 1\\}$ by attempting to find a linear function $z$ such that\n",
    "\n",
    "* $z = b + \\sum w_{i}x_{i}$\n",
    "\n",
    "* $y = 1$ if $z >= 0$ else\n",
    "$y = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multilayer Perceptron\n",
    "* Perceptron can only solve linearly separable problems.\n",
    "\n",
    "<center><img src=\"../support/mlp_mnist.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multilayer Perceptron Example\n",
    "\n",
    "MNIST dataset\n",
    "\n",
    "* 70K grayscale images (28x28)\n",
    "* Picture of a digit plus label\n",
    "\n",
    "Let's download the data set           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "mx.random.seed(42)\n",
    "\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "After running the above source code, the entire MNIST dataset should be fully loaded into memory. Note that for large datasets it is not feasible to pre-load the entire dataset first like we did here. What is needed is a mechanism by which we can quickly and efficiently stream data directly from the source. MXNet Data iterators come to the rescue here by providing exactly that. Data iterator is the mechanism by which we feed input data into an MXNet training algorithm and they are very simple to initialize and use and are optimized for speed. During training, we typically process training samples in small batches and over the entire training lifetime will end up processing each training example multiple times. In this tutorial, we'll configure the data iterator to feed examples in mini-batches of 100. Keep in mind that each example is a 28x28 grayscale image and the corresponding label.\n",
    "\n",
    "Image batches are commonly represented by a 4-D array with shape `(batch_size, num_channels, width, height)`. For the MNIST dataset, since the images are grayscale, there is only one color channel. Also, the images are 28x28 pixels, and so each image has width and height equal to 28. Therefore, the shape of input is `(batch_size, 1, 28, 28)`. Another important consideration is the order of input samples. When feeding training examples, it is critical that we don't feed samples with the same label in succession. Doing so can slow down training.\n",
    "Data iterators take care of this by randomly shuffling the inputs. Note that we only need to shuffle the training data. The order does not matter for test data.\n",
    "\n",
    "The following source code initializes the data iterators for the MNIST dataset. Note that we initialize two iterators: one for train data and one for test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "* Grayscale: one byte for color channel\n",
    "* Input data is `(batch_size, 1, 28, 28)`\n",
    "* Must shuffle training data with each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset, DataLoader and Transforms\n",
    "[Dataset](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.Dataset) - used to represent collection of data, includes methods to load/parse data on disk.  \n",
    "[DataLoader](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.DataLoader) - mini-batches of data from Dataset, iterator interface, can load data in parallel.  \n",
    "[Transforms](https://mxnet.incubator.apache.org/api/python/gluon/data.html#vision-transforms) - Transformations that can applied on data for augmentation, multiple transforms can composed to apply sequentially on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_dataset = gluon.data.vision.MNIST(train=True).transform_first(transforms.ToTensor())\n",
    "train_data = gluon.data.DataLoader(train_dataset, \n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)\n",
    "\n",
    "val_dataset = gluon.data.vision.MNIST(train=False).transform_first(transforms.ToTensor())\n",
    "val_data = gluon.data.DataLoader(val_dataset, \n",
    "                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(mnist['train_data'][i][0], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label: %s' % (mnist['train_label'][0:10],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multilayer Perceptron\n",
    "\n",
    "* Simplest DL solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first approach makes use of a [Multilayer Perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) to solve this problem. We'll define the MLP using MXNet's imperative approach.\n",
    "\n",
    "MLPs consist of several fully connected layers. A fully connected layer or FC layer for short, is one where each neuron in the layer is connected to every neuron in its preceding layer. From a linear algebra perspective, an FC layer applies an [affine transform](https://en.wikipedia.org/wiki/Affine_transformation) to the *n x m* input matrix *X* and outputs a matrix *Y* of size *n x k*, where *k* is the number of neurons in the FC layer. *k* is also referred to as the hidden size. The output *Y* is computed according to the equation *Y = W X + b*. The FC layer has two learnable parameters, the *m x k* weight matrix *W* and the *m x 1* bias vector *b*.\n",
    "\n",
    "In an MLP, the outputs of most FC layers are fed into an activation function, which applies an element-wise non-linearity. This step is critical and it gives neural networks the ability to classify inputs that are not linearly separable. Common choices for activation functions are sigmoid, tanh, and [rectified linear unit](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) (ReLU). In this example, we'll use the ReLU activation function which has several desirable properties and is typically considered a default choice.\n",
    "\n",
    "The following code declares three fully connected layers with 128, 64 and 10 neurons each.\n",
    "The last fully connected layer often has its hidden size equal to the number of output classes in the dataset. Furthermore, these FC layers uses ReLU activation for performing an element-wise ReLU transformation on the FC layer output.\n",
    "\n",
    "To do this, we will use [Sequential layer](http://mxnet.io/api/python/gluon/gluon.html#mxnet.gluon.nn.Sequential) type. This is simply a linear stack of neural network layers. `nn.Dense` layers are nothing but the fully connected layers we discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(128, activation='relu'))\n",
    "    net.add(nn.Dense(64, activation='relu'))\n",
    "    net.add(nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Initialize parameters and optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The following source code initializes all parameters received from parameter dict using [Xavier](http://mxnet.io/api/python/optimization/optimization.html#mxnet.initializer.Xavier) initializer\n",
    "to train the MLP network we defined above.\n",
    "\n",
    "For our training, we will make use of the stochastic gradient descent (SGD) optimizer. In particular, we'll be using mini-batch SGD. Standard SGD processes train data one example at a time. In practice, this is very slow and one can speed up the process by processing examples in small batches. In this case, our batch size will be 100, which is a reasonable choice. Another parameter we select here is the learning rate, which controls the step size the optimizer takes in search of a solution. We'll pick a learning rate of 0.02, again a reasonable choice. Settings such as batch size and learning rate are what are usually referred to as hyper-parameters. What values we give them can have a great impact on training performance.\n",
    "\n",
    "We will use [Trainer](http://mxnet.io/api/python/gluon/gluon.html#trainer) class to apply the\n",
    "[SGD optimizer](http://mxnet.io/api/python/optimization/optimization.html#mxnet.optimizer.SGD) on the\n",
    "initialized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpus = mx.test_utils.list_gpus()\n",
    "ctx = mx.gpu(0) if gpus else mx.cpu()\n",
    "\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd',\n",
    "                        {'learning_rate': 0.02})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc at epoch 0: accuracy=0.801883\n",
      "Training acc at epoch 1: accuracy=0.903100\n",
      "Training acc at epoch 2: accuracy=0.918900\n",
      "Training acc at epoch 3: accuracy=0.927500\n",
      "Training acc at epoch 4: accuracy=0.935367\n",
      "Training acc at epoch 5: accuracy=0.941183\n",
      "Training acc at epoch 6: accuracy=0.946267\n",
      "Training acc at epoch 7: accuracy=0.950183\n",
      "Training acc at epoch 8: accuracy=0.953617\n",
      "Training acc at epoch 9: accuracy=0.956833\n",
      "CPU times: user 1min 3s, sys: 4.83 s, total: 1min 8s\n",
      "Wall time: 50.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epoch = 10\n",
    "metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    for data, labels in train_data:\n",
    "        data = data.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        with ag.record():\n",
    "            predictions = net(data)\n",
    "\n",
    "            loss = softmax_cross_entropy_loss(predictions, labels)\n",
    "        loss.backward()\n",
    "            \n",
    "        metric.update(labels, predictions) # Informational purposes only\n",
    "        \n",
    "        # Make one step of parameter update.\n",
    "        # Trainer needs to know the batch size\n",
    "        # to normalize the gradient by 1/batch_size.\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    print('Training acc at epoch %d: %s=%f'%(i, name, acc))\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction\n",
    "\n",
    "* Also called _Inference_\n",
    "* Evaluate against unseen data\n",
    "* Ensure model is not overfit\n",
    "* We want models that generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: accuracy=0.954500\n"
     ]
    }
   ],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "for data, labels in val_data:\n",
    "    data = data.as_in_context(ctx)\n",
    "    labels = labels.as_in_context(ctx)    \n",
    "    predictions = net(data) # No backpropagation\n",
    "    metric.update(labels, predictions)\n",
    "\n",
    "print('validation acc: %s=%f'%metric.get())\n",
    "assert metric.get()[1] > 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 7, ground truth label: 7\n",
      "prediction: 2, ground truth label: 2\n",
      "prediction: 1, ground truth label: 1\n",
      "prediction: 0, ground truth label: 0\n",
      "prediction: 4, ground truth label: 4\n",
      "prediction: 1, ground truth label: 1\n",
      "prediction: 4, ground truth label: 4\n",
      "prediction: 9, ground truth label: 9\n",
      "prediction: 6, ground truth label: 5\n",
      "prediction: 9, ground truth label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEXRJREFUeJztnXtMFFcbxg9SiCBUESOg0VAJaTGYYCRiNFolptFY0VQRXUPRthJs4yWatjHRGjVR1JbGGyQCoTTFbWypIqE2YlUQvEBVEi94ySrFABa5usvuAjvn+f7wm/l2hYVZmBnKfu8veRNdVvfhvOc8c+Y9Z856AGAEQRDE8GfEUAsgCIIglIEMnSAIwk0gQycIgnATyNAJgiDcBDJ0giAIN4EMnSAIwk0gQycIgnATyNAJgiDcBDJ0giAIN+EtLT/Mw8ND88dSAXiQDtJBOkiHu+noDZqhEwRBuAlk6ARBEG4CGXofHDx4kB07doxdv36dAZCioKCAbd26dajlEQRBOGJvVGoHYwxax0B1lJeXg3PuNJqamjBlyhTVdfQX06ZNA+cce/bs0UyHn58fCgoKpLaoqalBWFiYJnn5t/QP0jF8dQQGBmL27NlSjB07FhkZGUhJScHs2bOHTXv0qo0MvWe8aeYvXryAXq9HZWUlKisrpde///77Ie+gn3/+OQRBwGeffaaZjsjISAiCIAXnHLt371Y9L2LMmzcPbW1t/b5v9erVeOedd4YkL0lJSQCA3bt3w9PTU7X2CAkJwaNHj5CdnY3w8HBZ2gICApCUlAQvLy/N2sPVUENHYmIiioqK8PLlS4fx3djYiK6uLunvw6U9yNBl6FiwYAFsNhs456ivr0d4eDj8/f3BGIO3tze8vb3x/PlzcM6Rl5c3pB2UMYacnBxYrVbNdAQHB8NgMAypoaelpcFoNPb7vjNnzqCsrEzzvIwfPx6vXr2CiK+vryrtERgYiI6ODthsNpSXl8vSFhAQgObmZlitVkRGRireHmPGjMHZs2fx+PFjeHl59XrR0KKfMsYQEREBvV6Pzs5OdHZ2Sn21v1C7fyjVHr2FptsWnZGcnMw2bdrE/vnnH2Y2m9nJkyfZ06dP2YMHDzTXMnnyZObh4cFevHjBYmJi2PPnz6WfHTx4kDHGWHBwMGOMsd9++01zffbExMQwnU7H/vjjD00+b+/evSw+Pp6Fhob2+NkHH3zARowYwW7fvs0KCgpU0/DWW2+xpUuXynpvWVkZ2759O/Pz82Mmk0k1TW+ydOlS5u/vzxhj7OrVq8xisSj+GUFBQezKlSvMx8eHnTlzhq1YsULWvzt27BgLCAhgO3bsYPfu3VNU0+bNm9nevXvZ22+/zRhjLCAggDHGWGNjo6KfI5d3332XJSQk9PmexsZG9vTpU9W1TJ06lU2aNIkxxphOp2Pvv/8+45yz48ePswsXLiiXi3/DDL21tbXHVdJqtcJgMPQb165dw4IFCxS90oeFhWHcuHE9Xq+rq0NdXZ2kccWKFZrOON6M5ORkcM6xfPlyTXRwzh1m5vYzdPHPzc3NmD9/vmo6EhISIAgCsrOz+33vgQMHIAgCgoODNcnLyJEjMXLkSNTW1kqz87Vr16qSl9WrV0v9sK/fzz6io6PBOceNGzcwevRoRdsjNDQUHR0dDmO4tLQUpaWlvY4lNfpHUFAQMjMzodPpwBjDokWLYLFY0N7ejvb2dlgsFpSVleHo0aNISEhAUFAQ/Pz8VBsvjDHExMSgsLCwR9vYh81mQ0NDA86dOwdvb2/ZOnrV9m8w9Pj4eBw4cAA6nQ4HDhzAlStX0N7eDs452traem2AV69eSX/vq/Sh1IA9dOgQuru70d3dDc45DAYDRo0apWoH7S9qamrQ2trab6dUQkdVVRUA9NohOzo6elyU1dARExMDs9mMly9fSmWwvuLRo0eaGnpsbCxiY2MlMxcEQZW8hISEoKioCJxzbN++Xdb/Hx0dDaPRCM45tmzZonh7nD592qlhWSwWpKamOjUrJXT4+flJpdB169ZJr9uvK0yZMgUjRoxwKacDbY9Zs2ahqKgIFotFagfxwlJaWoqsrCwIgoBnz56Bc45Xr16hra0NO3fulK3jX2vovUVgYCBWrlyJMWPGID4+3iGWLFmC4OBgmM1mcM7xzTffqDpgP/74Y8nIOecwGo0uzYqV0mHfScPDw6UFHbV1LF++HC0tLT1m6Pn5+cjPz0dSUhKWLVuG9PR06We7du1SXEdZWRm6u7sRGxvb7+85btw46QKklaHn5OQgJydHMvQ7d+6okpcrV64AAGpra2VfzHfu3AnOOYqLixXPS1hYGKxWKzjnqKurw927d3uYutFoxMSJE1VpD29vb/z111/gnCMzM9OliZaSOsQoKipymJHfv38fer0ePj4+8PHxkd738OFDREVFwWAwoKurS5oU9dZfh72h9xcbNmyQOlBft3RK6EhPT3fonKdPn9akYziLbdu2Ydu2beCc48mTJ6rqCA8Ph9FodCitNDc3Izc3F6NGjXIYPGFhYdJ7Ozs7sX//fqeLYq7qSE5OhtVqRUNDg6zf89SpU+Cco7q6us+FOSXzIpYBAcBms2HOnDmq5OXy5cvgnOPWrVv9Ljr6+vri5MmT0uRHjX66fv16cM7x+PFjMMbg4+ODL7/8Es3NzWhubgbnHABQU1Mju/wiV4e/vz+ysrLAOYfJZEJAQMCAcqdEe/j4+OD48eOST5hMJqSnpzu96NbX1yM6OtqhfPZ/aeghISEwmUwAgA0bNijeQe2jsrJS2tJ08eJFXLx4UdbtvtI67CMvLw95eXngnCMpKUlVHfZbFDnnePDgAYKCgpy+f8+ePQ7mHxERoYiO8vJyCILQ592YGOHh4TCZTLDZbFi5cqUmeVm8eDHssVgsquVFNHTOOR4+fIiKigqsXr26R2RlZcFgMEjvlbMTZiDtsXHjRnDO8cknnzi8XlVVhaqqKgetcseOXB1btmwB5xytra0IDQ0d0HhSqj10Oh06OzulEsrChQt7fZ+npyfCw8Nx8OBBtLW1SXc3AHD58mXZ20ndxtAzMjKk2tzMmTNVG7CTJk2Sbp1MJhMiIiKcGpQaA6W3WLRoEcxmM8xmM2prax1u4dTQYW/oNTU1/T5MFRYWJtUFlTL0gIAAtLW1ya5JZ2dnQxAEWbN5pfKyb98+B0PPyspSLS/z5893WEOSE83NzbL67kDao6KiApxznD9/3uH1jo4Oh9JDTk6O4u0hPuB28+ZNl3OmdF4SExOlmnlrayv27NmDH3/8Ebdu3cKtW7dQXl6O8vJy1NfXQxAEaU3DfkY/bdo02TrcwtCXLFki7RNftmyZqgPWfnZz6tQpzTpGX3H06FHJNEpKSlTXERkZKXuhk7HXs+OamhoAr+vXzjS6oiMkJASCIMj+fcXZ/NWrVzXLS0lJiZQXi8Xi8mzRVR2BgYFYsWIFcnNzJTPIzc11iJkzZ0q5u3Tpkmr9VJyh19XVISoqCikpKSgtLZUmAmK5x2w2Y8aMGYrqEC8YXV1dOHHiBObOnety7pRqD19fX1RUVEizdHEMiJMbZxdbQRBw/fp1TJo0ySUdvQWd5UIQBOEuDLcZurgAcv/+fVlPoQ1Ux7p166SdLdXV1QOqmyuh4824fv26dGX/9NNPVdeRl5cnzbTk/P9q1NB9fX1RW1vb7wI4Y69n82L7yHl6VYm8fPjhh9KMDICsYwnU6h/28d5774FzjufPn8veqz4QHePGjXPYnifG3bt3cffuXUydOhWNjY3gnKOwsFBRHfazYLHP5efnY/PmzUhLS0NKSgpmzJghRUpKikt3TwNpj7Fjx+KHH37AkydPUFlZiV9//RVFRUV49uyZVI60j4KCAowdO9ZlHb1qG06GLg7s7u5uLF68WLWEjB8/3qHhB1tuUWrATpw4ESaTCY2NjS5vVxyojpcvX8oy9ODgYCxfvtxhR4zRaHRac3dVh1hGefr0KVJSUhwiIyMDGRkZKCkpwZMnTyS9chZQlcjL+vXrYc+btWSt+seb8eeff4JzjoSEBNV1rFq1ChaLRTLYX375xWGbXnZ2tlRbVrKW/9NPP7m0liCWp/o7EkKNvFy+fNlhQdtqteKrr74a8Fk/w97QxS1BVVVVqnZQsfNx/vqpusHOzpXqGN99953DbhstdMg19NOnTzvsUW9paUFcXJxiOqZPn45r166hq6urx5OqJpMJJpNJupiIodYZKm+GWD+3WCywWCyy9smroUMM8UInmsa8efM00bFq1SoUFxdDr9f3GDNifVluPV+uDk9PT8TGxqKpqQmtra2yz2sRBAFHjx7VLC+HDx+GzWaT1v8459i0adOg8jJsDT0xMRGJiYkQBAEWiwWLFi1StYPaP0TU10KFK6FEe5w7dw6cc+j1euj1ek10yDH0qqoqtLS0OJhpfw/VDLQ95s6di+TkZIew//mlS5dcKhENNi+hoaFSuaWhoUH2Pnk1+ocYxcXFKC4u7nNRWgsdb8YXX3wBzl8/Mdlf6WygOuLj46HT6XotbbwZFRUVmrTH119/LW1NFKOhoQEjR44cVF6GpaGPHz8eLS0t0pOKpaWlqndQe0OPjo5GUFBQjxDr915eXtJrkZGRKCgokCI/P1968EaJ9hC3qq1cubLf/dVKtUdTU5PUFmvXrsXatWt7bJkDeh4JoMVA6S1OnDghGXpMTIzqOjZu3AiRzMxMZGZmapKXvsJoNMJoNKKzs9Ol2bmaeWGMYcSIESgtLQXnHMePH1dVh3g3a7PZUFhYiMLCQsyfPx8lJSWaGvrChQt7mLnVasWSJUsGnZdhZ+ienp74+++/Xd5LO9iE2Bu6sygrK8PPP/8sdVBnceTIEUU6RlxcnHQ7qaWh79+/v9dDuJwdziUuSqk9UJyF/VO9avUP+9i1axcAoKOjQ7qwa5EXZyE+4i/WiodKh7OYM2eO9KCesz3XSuiYN29ej7H44MEDh5LMmTNnVG+PkydPSp8nHuP70UcfKZKXYWfo4rfxiOHqU5EDTcjNmzddXmix2WzS4V3l5eU4dOgQDh06JJWHBtse4qPstbW18PT0lLWQokR72D/O35ehG41GVFdXIyIiQtZZGmoZh/0MXa3+YR+VlZUAXp+rMtTnfzPGHE4DvXDhAhhjGD16tOxv11Lb0BljSE1NldannK1zDFaHr68vrl696nSsVlRUyDoHZzA6Ro8e7VAzF+8UlOofw8rQw8LCpJMWU1NTkZqaCg8PD80GyuHDh3HkyBEpepuJnz9/Xvr59OnTVesYo0aNkrZ9paWlDWowDUTHsmXLoNfr+zR0Lb/goq/IycmRzpJRW4eXlxcaGhoAAAaDQfO89Bb2hv77779j8+bNqK2tVfXBIlcjODhYKuXNmjVLNR0TJkzAnTt3pBIU5xwtLS1IT09XPS/+/v4Opcm6uroeh3MNtn8MK0MX95tzzrFgwYI+zzwf6g6qtg4vLy8YDAZUVlYO+iS5wejQ6XS4efMmBEHAjRs3sGbNGqxZswY6nc6l71dVMy8mkwlmsxn79u1TXYenpycuXrwIALINU+32sDd0e2Pv76v41M7LmzFlypQ+F22V1LF161Zs3boVZ8+eRUhIiCZ5WbduHYD/rS0NtETal45hY+hxcXEOCwn/74ZOOuTH7du3XRo8g9UxefJkFBcXu3yHolZ7xMXFobq6GtXV1UhPT8eECRNUPYd8MHHv3j10dnb2ehzAcO+n9hfW3NxcVXQMG0NPS0tzWAiNiopCVFTUkA6UoeoYpIN0uKuOMWPGoLW11eELKdylPdrb2wEAJpNJka3Pcj32X/Gdos6or69nUVFRrKmpaailEAShMG1tbdL3jrobJ06cYDt27GDffvutw/cSq43Hf6842nzY60VNTQHgQTpIB+kgHe6mozc0NXSCIAhCPej4XIIgCDeBDJ0gCMJNIEMnCIJwE8jQCYIg3AQydIIgCDeBDJ0gCMJNIEMnCIJwE8jQCYIg3AQydIIgCDeBDJ0gCMJNIEMnCIJwE8jQCYIg3AQydIIgCDeBDJ0gCMJNIEMnCIJwE8jQCYIg3AQydIIgCDeBDJ0gCMJNIEMnCIJwE8jQCYIg3AQydIIgCDeBDJ0gCMJNIEMnCIJwE/4DziMlcmzWpzoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    d = mnist['test_data'][i][0]\n",
    "    x  = (mx.nd.expand_dims(mx.nd.array(d), axis=0))\n",
    "    prediction = net(x.as_in_context(ctx))\n",
    "    prediction = np.squeeze(prediction.asnumpy())\n",
    "    prediction = np.argmax(prediction)\n",
    "    print('prediction: %s, ground truth label: %s' % (prediction, mnist['test_label'][i]))\n",
    "    plt.imshow(d, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label: %s' % (mnist['test_label'][0:10],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy\n",
    "\n",
    "95% accuracy in a few seconds with a very simple MLP!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems with MLP\n",
    "\n",
    "MLP is not sufficient for more complex problems\n",
    "\n",
    "* Sensitive to position within image.\n",
    "* we don't exploit the spatial correlation in the image.\n",
    "* Can end up with many parameters.\n",
    "* Binary Threshold unit cannot tell if two single bit features are the same(think of an XOR).  \n",
    "Positive cases (same): (1,1) -> 1; (0,0) -> 1  \n",
    "Negative cases (different): (1,0) -> 0; (0,1) -> 0"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
